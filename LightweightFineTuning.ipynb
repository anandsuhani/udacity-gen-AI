{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: I decided to use the LoRA technique, as advised, because I was most comfortable with what I was familiar with.\n",
    "* Model: Again, decided to use GPT 2 because it was the most recommended in the instructions and FAQ\n",
    "* Evaluation approach:I decided to use the imdb data set alongside the trainer API from Hugging Face, to ensure that any mistakes I made were not due to the usage of an unlearned evaluation method. \n",
    "* Fine-tuning dataset: I decided to fine tune a small portion of the imdb data set, so that the training would loop faster. I ended up choosing to train 500 examples from the imdb training split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2ForSequenceClassification, GPT2Tokenizer\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2')\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "checkpoint_dir = \"/workspace/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoints = sorted(os.listdir(checkpoint_dir), reverse=True)\n",
    "if len(checkpoints) > 3:\n",
    "    os.remove(os.path.join(checkpoint_dir, checkpoints[-1]))  \n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_latest.pth\")\n",
    "torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6db3698c6134f80b29c69b5673befcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1323c990c54126893ef2717979e29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 15:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model: {'eval_loss': 0.7861188650131226, 'eval_accuracy': 0.5074, 'eval_runtime': 932.5803, 'eval_samples_per_second': 5.361, 'eval_steps_per_second': 0.67}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "dataset=load_dataset(\"imdb\")\n",
    "\n",
    "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=23)\n",
    "train_data = split_dataset[\"train\"]\n",
    "test_data = split_dataset[\"test\"]\n",
    "\n",
    "train_data.save_to_disk(\"data/imdb_custom_train\")\n",
    "test_data.save_to_disk(\"data/imdb_custom_test\")\n",
    "\n",
    "\n",
    "tokenized_train = train_data.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "original_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "original_results = original_trainer.evaluate()\n",
    "print(\"Original Model:\", original_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)\n",
    "from transformers import TrainingArguments\n",
    "from datasets import load_from_disk\n",
    "\n",
    "train_data = load_from_disk(\"data/imdb_custom_train\")\n",
    "test_data = load_from_disk(\"data/imdb_custom_test\")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",             \n",
    "    logging_steps=10,                 \n",
    "    evaluation_strategy=\"epoch\",     \n",
    "    save_strategy=\"epoch\",    \n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\"],  \n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "model.config.pad_token_id = model.config.eos_token_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 8:53:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.489749</td>\n",
       "      <td>0.773800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.567400</td>\n",
       "      <td>0.460634</td>\n",
       "      <td>0.792800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.465200</td>\n",
       "      <td>0.462180</td>\n",
       "      <td>0.795800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15000, training_loss=0.5435675119876862, metrics={'train_runtime': 31994.656, 'train_samples_per_second': 1.875, 'train_steps_per_second': 0.469, 'total_flos': 1966555791360000.0, 'train_loss': 0.5435675119876862, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"/tmp/peft-gpt2-imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/results\",\n",
    "    per_device_eval_batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 26:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model: {'eval_loss': 0.4621804654598236, 'eval_accuracy': 0.7958, 'eval_runtime': 1603.8345, 'eval_samples_per_second': 3.118, 'eval_steps_per_second': 0.779}\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModelForSequenceClassification\n",
    "\n",
    "peft_model = PeftModelForSequenceClassification.from_pretrained(model,\n",
    "    \"/tmp/peft-gpt2-imdb\"\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "peft_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "fine_tuned_results = peft_trainer.evaluate()\n",
    "print(\"Fine-Tuned Model:\", fine_tuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model: {'eval_loss': 0.7861188650131226, 'eval_accuracy': 0.5074, 'eval_runtime': 932.5803, 'eval_samples_per_second': 5.361, 'eval_steps_per_second': 0.67}\n",
      "Fine-Tuned Model: {'eval_loss': 0.4621804654598236, 'eval_accuracy': 0.7958, 'eval_runtime': 1603.8345, 'eval_samples_per_second': 3.118, 'eval_steps_per_second': 0.779}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Model:\", original_results)\n",
    "print(\"Fine-Tuned Model:\", fine_tuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3ebc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0766a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef7820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86121564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37ae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
